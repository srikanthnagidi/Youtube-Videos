{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent() # From here we generate a random user agent\n",
    "proxies = [] # Will contain proxies [ip, port]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProx():\n",
    "    proxies_req = Request('https://www.sslproxies.org/')\n",
    "    proxies_req.add_header('User-Agent', ua.random)\n",
    "    proxies_doc = urlopen(proxies_req).read().decode('utf8')\n",
    "    soup = BeautifulSoup(proxies_doc, 'html.parser')\n",
    "    proxies_table = soup.find(id='proxylisttable')\n",
    "         # Save proxies in the array\n",
    "    global proxies\n",
    "    proxies=[]\n",
    "    for row in proxies_table.tbody.find_all('tr'):\n",
    "        proxies.append({\n",
    "        'ip':   row.find_all('td')[0].string,\n",
    "        'port': row.find_all('td')[1].string\n",
    "      })\n",
    "    #print(len(proxies))\n",
    "    #print(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getProx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "proxy_index = random.randint(0, len(proxies) - 1)\n",
    "proxy = proxies[proxy_index] \n",
    "req = Request('http://icanhazip.com')\n",
    "req.set_proxy(proxy['ip'] + ':' + proxy['port'], 'http')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"altmetricIDS.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Altmetrics_Id']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"youtube_links\"] = \"\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array(df['Altmetrics_Id'])\n",
    "ids[5255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_param  = {\"key\" : \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_alt_data = requests.get(\"https://api.altmetric.com/v1/id/1969481\", alt_param )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_data = json.loads(all_alt_data.text)\n",
    "alt_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_links = []\n",
    "html = requests.get('https://www.altmetric.com/details/' + str(403270) + '/video', alt_param).text\n",
    "bs = BeautifulSoup(html)\n",
    "possible_links = bs.find_all('a')\n",
    "for link in possible_links:\n",
    "    if link.has_attr('href') and 'youtube' in link.attrs['href']:\n",
    "        y_links.append(link.attrs['href'])\n",
    "y_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common import exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome = webdriver.Chrome('C:/ProgramData/chocolatey/bin/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome.get('https://www.altmetric.com/details/403270/video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pages(main_link):\n",
    "    myset= set()\n",
    "    chrome.get(main_link)\n",
    "    elements = chrome.find_elements_by_xpath(\"//a[@href]\")\n",
    "    for elem in elements:\n",
    "        if \"video/page:\" in elem.get_attribute(\"href\"):\n",
    "            myset.add(elem.get_attribute(\"href\"))\n",
    "    return myset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youtube_ids(link):\n",
    "    y_links = []\n",
    "    chrome.get(link)\n",
    "    elements = chrome.find_elements_by_xpath(\"//a[@href]\")\n",
    "    for elem in elements:\n",
    "        if \"youtube\" in elem.get_attribute(\"href\"):\n",
    "            y_links.append(elem.get_attribute(\"href\")[32:])\n",
    "    return y_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('youtube.csv', 'w')\n",
    "for i in range(len(ids)):\n",
    "    try:\n",
    "        getProx()\n",
    "        proxy_index = random.randint(0, len(proxies) - 1)\n",
    "        proxy = proxies[proxy_index] \n",
    "        req = Request('http://icanhazip.com')\n",
    "        req.set_proxy(proxy['ip'] + ':' + proxy['port'], 'http')\n",
    "        sleep(0.5)\n",
    "        y_links = get_youtube_ids('https://www.altmetric.com/details/' + str(ids[i]) + '/video')\n",
    "        myset = get_all_pages('https://www.altmetric.com/details/' + str(ids[i]) + '/video')\n",
    "        for link in myset:\n",
    "            y_links.extend(get_youtube_ids(link))\n",
    "        df.at[i, 'youtube_links'] = y_links\n",
    "        file.write(str(ids[i]) + \",\")\n",
    "        file.write(\" \".join(y_links) + \"\\n\")\n",
    "        \n",
    "    except exceptions.StaleElementReferenceException:\n",
    "        sleep(0.5)\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        my_ip = urlopen(req).read().decode('utf8')        \n",
    "        print('#' + str(n) + ': ' + my_ip)\n",
    "\n",
    "    except:  \n",
    "        # If error, delete this proxy and find another one\n",
    "        #global proxies\n",
    "        del proxies[proxy_index]\n",
    "        print('proxy deleted')\n",
    "        proxy_index = random.randint(0, len(proxies) - 1)\n",
    "        proxy = proxies[proxy_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[4, 'youtube_links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"youtube_links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_data['details_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_video(alt_id):\n",
    "    try:\n",
    "        response = requests.get(\"https://api.altmetric.com/v1/id/\" + str(alt_id))\n",
    "        if 'video' in dict(json.loads(response.content)):\n",
    "            return dict(json.loads(response.content))['video']\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"key\" : \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_content = \"https://www.googleapis.com/youtube/v3/videos?part=snippet&key=&id=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.googleapis.com/youtube/v3/videos?part=snippet,statistics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids[6733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alt_id in ids[6933:7133]:\n",
    "    mylist = []\n",
    "    alt_req = requests.get(\"https://api.altmetric.com/v1/id/\" + str(alt_id))\n",
    "    alt_rs= json.loads(alt_req.text)\n",
    "    mylist.append({str(alt_id) : alt_rs})\n",
    "    y_links = []\n",
    "    html = requests.get('https://www.altmetric.com/details/' + str(alt_id) + '/video').text\n",
    "    bs = BeautifulSoup(html)\n",
    "    possible_links = bs.find_all('a')\n",
    "    for link in possible_links:\n",
    "        if link.has_attr('href') and 'youtube' in link.attrs['href']:\n",
    "            y_links.append(link.attrs['href'])\n",
    "    youtube_data = []\n",
    "    for link in y_links:\n",
    "        param[\"id\"] = link[32:]\n",
    "        response_statistics = requests.get(url, param)\n",
    "        print(response_statistics.status_code)\n",
    "        json_statistics = json.loads(response_statistics.text)\n",
    "        youtube_data.append(json_statistics)\n",
    "    mylist.append({'youtube':youtube_data})\n",
    "    file = open(str(alt_id) + \".txt\", \"w+\")\n",
    "    json.dump(mylist, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"C:/Users/srika/Youtube_dataSet\"\n",
    "files = os.listdir(path)\n",
    "len(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(files)):\n",
    "    files[i] = os.path.abspath(path + \"/\" + files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"C:\\\\Users\\\\srika\\\\Youtube_dataSet\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame()\n",
    "col = ['cited_by_fbwalls_count', 'cited_by_feeds_count', 'cited_by_gplus_count', 'cited_by_msm_count', \n",
    "       'cited_by_posts_count', 'cited_by_rdts_count', 'cited_by_tweeters_count', 'cited_by_videos_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ['viewCount', 'likeCount',  'dislikeCount', 'favoriteCount','commentCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for file in files:\n",
    "    json_file = open(file, \"r\")\n",
    "    data = json.load(json_file)\n",
    "    df_.loc[i, \"altmetric_id\"] = file[31:-4]\n",
    "    for c in col:\n",
    "        try:\n",
    "            df_.loc[i, c] = data[0][file[31:-4]][c]\n",
    "        except KeyError:\n",
    "            df_.loc[i, c] = 0\n",
    "    i += 1\n",
    "    json_file.close\n",
    "    \n",
    "df_.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos = pd.DataFrame(columns = stats, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(files[:2])):\n",
    "    json_file = open(files[i], \"r\")\n",
    "    data = json.load(json_file)\n",
    "    df_videos.loc[i, 'altmetric_id'] = files[i][31:-4]\n",
    "    for stat in stats:\n",
    "        mylist = []\n",
    "        for j in range(len(data[1]['youtube'])):\n",
    "            try:\n",
    "                mylist.append(int(data[1]['youtube'][j]['items'][0]['statistics'][stat]))\n",
    "            except IndexError:\n",
    "                mylist.append(0)\n",
    "            except KeyError:\n",
    "                mylist.append(0)\n",
    "        print(stat, mylist)\n",
    "        df_videos.at[i, stat] = mylist\n",
    "    json_file.close()\n",
    "df_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_csv(\"altmetrics_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos.to_csv(\"videos.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_link = url_statistics +\"GSqdhz--yR8\"\n",
    "rs_st = requests.get(y_link)\n",
    "rs_st_d = json.loads(rs_st.text)\n",
    "rs_st_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_content = url_content + \"GSqdhz--yR8\"\n",
    "rs_ct = requests.get(y_link)\n",
    "rs_ct_d = json.loads(rs_st.text)\n",
    "rs_ct_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_media_columns = ['cited_by_fbwalls_count', 'cited_by_gplus_count', 'cited_by_msm_count', 'cited_by_posts_count', \n",
    "                        'cited_by_tweeters_count', 'cited_by_videos_count', 'cited_by_wikipedia_count', \n",
    "                        'cited_by_accounts_count',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['title', 'doi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ids[:100])):\n",
    "    rs = requests.get(\"https://api.altmetric.com/v1/id/\" + str(ids[i]))\n",
    "    if (rs.status_code == 200):\n",
    "        rs_json = json.loads(rs.text)\n",
    "        for col in cols:\n",
    "            try:\n",
    "                df.loc[i, col] = rs_json[col]\n",
    "            except KeyError:\n",
    "                df.loc[i, col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:100].to_csv(path_or_buf = \".\\\\sample_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_comments = \"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=_qUhIZcxNvE&key=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(response.text)\n",
    "json_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data[\"items\"][2]['snippet']['topLevelComment']['snippet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = 0\n",
    "dc = 0\n",
    "for j in len(json_data['items']):\n",
    "    lc + = json_data['items'][j][\"likeCount\"]\n",
    "    dc + = json_data['items'][j][\"likeCount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add author information\n",
    "def add_all_info(alt_id):\n",
    "    # create the dict\n",
    "    result = defaultdict(dict)\n",
    "    try:\n",
    "        # make the request\n",
    "        response = requests.get(\"https://api.altmetric.com/v1/id/\" + str(alt_id))\n",
    "\n",
    "        # add the values to the dict\n",
    "        if 'authors' in dict(json.loads(response.content)):\n",
    "            result['author_count'] = len(dict(json.loads(response.content))['authors'])\n",
    "            result['authors'] = ', '.join(dict(json.loads(response.content))['authors'])\n",
    "        else:\n",
    "            result['author_count'] = ''\n",
    "            result['authors'] = ''\n",
    "\n",
    "         # add the values to the dict\n",
    "        if 'doi' in dict(json.loads(response.content)):\n",
    "            result['doi'] = dict(json.loads(response.content))['doi']\n",
    "        else:\n",
    "            result['doi'] = ''\n",
    "\n",
    "        # add the abstract\n",
    "        if 'abstract' in dict(json.loads(response.content)):\n",
    "            result['abstract'] = dict(json.loads(response.content))['abstract']\n",
    "        else:\n",
    "            result['abstract'] = ''\n",
    "\n",
    "        # add the pubdate\n",
    "        if 'published_on' in dict(json.loads(response.content)):\n",
    "            result['pub_date'] = dict(json.loads(response.content))['published_on']\n",
    "        else:\n",
    "            result['pub_date'] = ''\n",
    "\n",
    "        # add the twitter posts count as of 2018/19\n",
    "        if 'cited_by_tweeters_count' in dict(json.loads(response.content)):\n",
    "            result['twitter_count_y18'] = dict(json.loads(response.content))['cited_by_tweeters_count']\n",
    "        else:\n",
    "            result['twitter_count_y18'] = ''\n",
    "\n",
    "        # add the title of the article\n",
    "        if 'title' in dict(json.loads(response.content)):\n",
    "            result['title'] =  dict(json.loads(response.content))['title']\n",
    "        else:\n",
    "            result['title'] = ''\n",
    "\n",
    "        # return the result\n",
    "        return result\n",
    "    except:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = add_all_info(702709 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_ = requests.get(\"https://api.altmetric.com/v1/id/\" + str(2394296))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_js = json.loads(rs_.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_js.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = open(\"temp.txt\", 'w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(rs_js, fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_js['cited_by_accounts_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_js['cited_by_videos_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_statistics = requests.get(url_statistics)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_statistics = json.loads(response_statistics.text)\n",
    "json_statistics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_statistics['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
